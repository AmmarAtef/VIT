{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    " \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os \n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting einops\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/00/919421f097de2a6ca2d9b4d9f3f596274e44c243a6ecca210cd0811032c0/einops-0.3.2-py3-none-any.whl\n",
      "Installing collected packages: einops\n",
      "Successfully installed einops-0.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers\n",
    "\n",
    "def pair(t):\n",
    "    return t if isinstance(t, tuple) else (t, t)\n",
    "\n",
    "# classes\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.attend = nn.Softmax(dim = -1)\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n",
    "\n",
    "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "\n",
    "        attn = self.attend(dots)\n",
    "\n",
    "        out = torch.matmul(attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout)),\n",
    "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout = dropout))\n",
    "            ]))\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "        return x\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.):\n",
    "        super().__init__()\n",
    "        image_height, image_width = pair(image_size)\n",
    "        patch_height, patch_width = pair(patch_size)\n",
    "\n",
    "        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n",
    "\n",
    "        num_patches = (image_height // patch_height) * (image_width // patch_width)\n",
    "        patch_dim = channels * patch_height * patch_width\n",
    "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
    "\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n",
    "            nn.Linear(patch_dim, dim),\n",
    "        )\n",
    "\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
    "\n",
    "        self.pool = pool\n",
    "        self.to_latent = nn.Identity()\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = self.to_patch_embedding(img)\n",
    "        b, n, _ = x.shape\n",
    "\n",
    "        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b = b)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x += self.pos_embedding[:, :(n + 1)]\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n",
    "\n",
    "        x = self.to_latent(x)\n",
    "        return self.mlp_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 1, 128]              --\n",
      "|    └─Rearrange: 2-1                    [-1, 1, 3072]             --\n",
      "|    └─Linear: 2-2                       [-1, 1, 128]              393,344\n",
      "├─Dropout: 1-2                           [-1, 2, 128]              --\n",
      "├─Transformer: 1-3                       [-1, 2, 128]              --\n",
      "├─Identity: 1-4                          [-1, 128]                 --\n",
      "├─Sequential: 1-5                        [-1, 10]                  --\n",
      "|    └─LayerNorm: 2-3                    [-1, 128]                 256\n",
      "|    └─Linear: 2-4                       [-1, 10]                  1,290\n",
      "==========================================================================================\n",
      "Total params: 394,890\n",
      "Trainable params: 394,890\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 7.87\n",
      "==========================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 1.51\n",
      "Estimated Total Size (MB): 1.52\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 1, 128]              --\n",
       "|    └─Rearrange: 2-1                    [-1, 1, 3072]             --\n",
       "|    └─Linear: 2-2                       [-1, 1, 128]              393,344\n",
       "├─Dropout: 1-2                           [-1, 2, 128]              --\n",
       "├─Transformer: 1-3                       [-1, 2, 128]              --\n",
       "├─Identity: 1-4                          [-1, 128]                 --\n",
       "├─Sequential: 1-5                        [-1, 10]                  --\n",
       "|    └─LayerNorm: 2-3                    [-1, 128]                 256\n",
       "|    └─Linear: 2-4                       [-1, 10]                  1,290\n",
       "==========================================================================================\n",
       "Total params: 394,890\n",
       "Trainable params: 394,890\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 7.87\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 1.51\n",
       "Estimated Total Size (MB): 1.52\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ViT(image_size = 32,\n",
    "    patch_size = 32,\n",
    "    num_classes = 10,\n",
    "    dim = 128,\n",
    "    depth = 6,\n",
    "    heads = 16,\n",
    "    mlp_dim = 256,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1)\n",
    "summary(model.to(device), (3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    \"\"\"\n",
    "        Run one train epoch\n",
    "    \"\"\"\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "\n",
    "        input_var = input.cuda()\n",
    "        target_var = target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        output = output.float()\n",
    "        loss = loss.float()\n",
    "        # measure accuracy and record loss\n",
    "        acc = accuracy(output.data, target_var)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(acc.item(), input.size(0))\n",
    "\n",
    "    print(f'Epoch: [{epoch}]\\t Loss {losses.val:.4f} ({losses.avg:.4f})\\t acc {top1.val:.3f} ({top1.avg:.3f})')\n",
    "    return top1.avg, losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(val_loader, model, criterion):\n",
    "    \"\"\"\n",
    "    Run evaluation\n",
    "    \"\"\"\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            input_var = input.cuda()\n",
    "            target_var = target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input_var)\n",
    "            loss = criterion(output, target_var)\n",
    "\n",
    "            output = output.float()\n",
    "            loss = loss.float()\n",
    "\n",
    "            # measure accuracy and record loss and acc\n",
    "            acc = accuracy(output.data, target_var)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(acc.item(), input.size(0))\n",
    "\n",
    "\n",
    "    print(f'Test\\t  accuracy: {top1.avg:.3f} (Err: {losses.avg:.3f} )\\n')\n",
    "\n",
    "    return top1.avg, losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=3):\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(topk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    correct_k = correct[:topk].reshape(-1).float().sum(0, keepdim=True)\n",
    "    res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to dataset/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22356a1611d4d3d921f96c31a71f801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=170498071), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting dataset/cifar-10-python.tar.gz to dataset/\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset=datasets.CIFAR10(\n",
    "    root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True)\n",
    ", batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "\n",
    "test_loader = DataLoader(\n",
    "        datasets.CIFAR10(root='dataset/', train=False, transform=transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "        ])),\n",
    "        batch_size=128, shuffle=False,\n",
    "        num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model):\n",
    "    best_acc = 0\n",
    "\n",
    "    model.cuda()\n",
    "\n",
    "    # define loss function (criterion) and optimizer\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), .1, momentum=.9,\n",
    "                                weight_decay=1e-4)\n",
    "    # print('Training {} model'.format(args.arch))\n",
    "    test_accs, test_losses = [], []\n",
    "    train_accs, train_losses = [], []\n",
    "    for epoch in range(0,400):\n",
    "\n",
    "        train_acc, train_loss = train(train_loader, model, criterion, optimizer, epoch)\n",
    "        train_accs.append(train_acc)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        acc, loss = testing(test_loader, model, criterion)\n",
    "        test_accs.append(acc)\n",
    "        test_losses.append(loss)\n",
    "\n",
    "    return {\"best_acc\": max(test_accs), \"test_accs\":test_accs, \"test_losses\": test_losses, \"train_acss\": train_accs, \"train_losses\": train_losses}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]\t Loss 1.2837 (1.2310)\t acc 85.000 (85.546)\n",
      "Test\t  accuracy: 82.610 (Err: 1.350 )\n",
      "\n",
      "Epoch: [1]\t Loss 1.2353 (1.2246)\t acc 87.500 (85.546)\n",
      "Test\t  accuracy: 82.690 (Err: 1.374 )\n",
      "\n",
      "Epoch: [2]\t Loss 1.0628 (1.2170)\t acc 90.000 (85.790)\n",
      "Test\t  accuracy: 81.810 (Err: 1.392 )\n",
      "\n",
      "Epoch: [3]\t Loss 1.2177 (1.1966)\t acc 86.250 (86.158)\n",
      "Test\t  accuracy: 82.770 (Err: 1.357 )\n",
      "\n",
      "Epoch: [4]\t Loss 1.0561 (1.1900)\t acc 91.250 (86.332)\n",
      "Test\t  accuracy: 82.540 (Err: 1.370 )\n",
      "\n",
      "Epoch: [5]\t Loss 1.1811 (1.1830)\t acc 90.000 (86.514)\n",
      "Test\t  accuracy: 83.570 (Err: 1.337 )\n",
      "\n",
      "Epoch: [6]\t Loss 1.1555 (1.1781)\t acc 86.250 (86.690)\n",
      "Test\t  accuracy: 83.420 (Err: 1.332 )\n",
      "\n",
      "Epoch: [7]\t Loss 1.2718 (1.1624)\t acc 85.000 (86.946)\n",
      "Test\t  accuracy: 83.140 (Err: 1.355 )\n",
      "\n",
      "Epoch: [8]\t Loss 1.1678 (1.1539)\t acc 83.750 (87.252)\n",
      "Test\t  accuracy: 82.790 (Err: 1.376 )\n",
      "\n",
      "Epoch: [9]\t Loss 1.3423 (1.1448)\t acc 78.750 (87.340)\n",
      "Test\t  accuracy: 83.910 (Err: 1.322 )\n",
      "\n",
      "Epoch: [10]\t Loss 0.9938 (1.1383)\t acc 95.000 (87.716)\n",
      "Test\t  accuracy: 83.360 (Err: 1.352 )\n",
      "\n",
      "Epoch: [11]\t Loss 1.1875 (1.1277)\t acc 85.000 (87.956)\n",
      "Test\t  accuracy: 84.060 (Err: 1.346 )\n",
      "\n",
      "Epoch: [12]\t Loss 0.9903 (1.1227)\t acc 90.000 (87.944)\n",
      "Test\t  accuracy: 84.930 (Err: 1.284 )\n",
      "\n",
      "Epoch: [13]\t Loss 1.1251 (1.1086)\t acc 87.500 (88.054)\n",
      "Test\t  accuracy: 83.590 (Err: 1.345 )\n",
      "\n",
      "Epoch: [14]\t Loss 1.0415 (1.1087)\t acc 88.750 (88.170)\n",
      "Test\t  accuracy: 82.590 (Err: 1.380 )\n",
      "\n",
      "Epoch: [15]\t Loss 1.3305 (1.0952)\t acc 83.750 (88.432)\n",
      "Test\t  accuracy: 83.660 (Err: 1.326 )\n",
      "\n",
      "Epoch: [16]\t Loss 1.1453 (1.0835)\t acc 91.250 (88.488)\n",
      "Test\t  accuracy: 83.750 (Err: 1.311 )\n",
      "\n",
      "Epoch: [17]\t Loss 0.9536 (1.0858)\t acc 95.000 (88.710)\n",
      "Test\t  accuracy: 82.600 (Err: 1.374 )\n",
      "\n",
      "Epoch: [18]\t Loss 0.8027 (1.0772)\t acc 92.500 (88.934)\n",
      "Test\t  accuracy: 83.350 (Err: 1.377 )\n",
      "\n",
      "Epoch: [19]\t Loss 1.1468 (1.0601)\t acc 91.250 (89.286)\n",
      "Test\t  accuracy: 83.020 (Err: 1.372 )\n",
      "\n",
      "Epoch: [20]\t Loss 1.0952 (1.0568)\t acc 87.500 (89.306)\n",
      "Test\t  accuracy: 83.860 (Err: 1.308 )\n",
      "\n",
      "Epoch: [21]\t Loss 1.0804 (1.0412)\t acc 88.750 (89.594)\n",
      "Test\t  accuracy: 84.120 (Err: 1.348 )\n",
      "\n",
      "Epoch: [22]\t Loss 1.1160 (1.0459)\t acc 87.500 (89.526)\n",
      "Test\t  accuracy: 83.600 (Err: 1.337 )\n",
      "\n",
      "Epoch: [23]\t Loss 1.0732 (1.0393)\t acc 85.000 (89.646)\n",
      "Test\t  accuracy: 83.650 (Err: 1.361 )\n",
      "\n",
      "Epoch: [24]\t Loss 1.0451 (1.0246)\t acc 90.000 (89.796)\n",
      "Test\t  accuracy: 84.000 (Err: 1.349 )\n",
      "\n",
      "Epoch: [25]\t Loss 1.0492 (1.0117)\t acc 91.250 (90.024)\n",
      "Test\t  accuracy: 83.480 (Err: 1.385 )\n",
      "\n",
      "Epoch: [26]\t Loss 1.3419 (1.0084)\t acc 83.750 (90.192)\n",
      "Test\t  accuracy: 82.560 (Err: 1.433 )\n",
      "\n",
      "Epoch: [27]\t Loss 1.3464 (1.0015)\t acc 83.750 (90.168)\n",
      "Test\t  accuracy: 84.310 (Err: 1.317 )\n",
      "\n",
      "Epoch: [28]\t Loss 1.1968 (0.9965)\t acc 82.500 (90.466)\n",
      "Test\t  accuracy: 83.480 (Err: 1.346 )\n",
      "\n",
      "Epoch: [29]\t Loss 0.8414 (0.9938)\t acc 92.500 (90.476)\n",
      "Test\t  accuracy: 84.210 (Err: 1.349 )\n",
      "\n",
      "Epoch: [30]\t Loss 0.9576 (0.9899)\t acc 92.500 (90.588)\n",
      "Test\t  accuracy: 83.090 (Err: 1.396 )\n",
      "\n",
      "Epoch: [31]\t Loss 0.9943 (0.9865)\t acc 86.250 (90.700)\n",
      "Test\t  accuracy: 82.770 (Err: 1.437 )\n",
      "\n",
      "Epoch: [32]\t Loss 1.0570 (0.9768)\t acc 91.250 (90.880)\n",
      "Test\t  accuracy: 83.560 (Err: 1.328 )\n",
      "\n",
      "Epoch: [33]\t Loss 1.0639 (0.9698)\t acc 90.000 (90.922)\n",
      "Test\t  accuracy: 83.720 (Err: 1.374 )\n",
      "\n",
      "Epoch: [34]\t Loss 1.2148 (0.9571)\t acc 87.500 (91.068)\n",
      "Test\t  accuracy: 84.630 (Err: 1.353 )\n",
      "\n",
      "Epoch: [35]\t Loss 0.9432 (0.9538)\t acc 93.750 (91.324)\n",
      "Test\t  accuracy: 83.200 (Err: 1.422 )\n",
      "\n",
      "Epoch: [36]\t Loss 0.8239 (0.9589)\t acc 88.750 (91.264)\n",
      "Test\t  accuracy: 83.910 (Err: 1.402 )\n",
      "\n",
      "Epoch: [37]\t Loss 0.7757 (0.9370)\t acc 95.000 (91.584)\n",
      "Test\t  accuracy: 84.140 (Err: 1.360 )\n",
      "\n",
      "Epoch: [38]\t Loss 1.2827 (0.9376)\t acc 85.000 (91.574)\n",
      "Test\t  accuracy: 83.630 (Err: 1.356 )\n",
      "\n",
      "Epoch: [39]\t Loss 0.6832 (0.9227)\t acc 98.750 (91.862)\n",
      "Test\t  accuracy: 83.360 (Err: 1.440 )\n",
      "\n",
      "Epoch: [40]\t Loss 0.9578 (0.9244)\t acc 91.250 (91.834)\n",
      "Test\t  accuracy: 83.400 (Err: 1.449 )\n",
      "\n",
      "Epoch: [41]\t Loss 0.8282 (0.9197)\t acc 96.250 (92.072)\n",
      "Test\t  accuracy: 83.680 (Err: 1.400 )\n",
      "\n",
      "Epoch: [42]\t Loss 0.8258 (0.9090)\t acc 93.750 (91.992)\n",
      "Test\t  accuracy: 84.310 (Err: 1.366 )\n",
      "\n",
      "Epoch: [43]\t Loss 0.9278 (0.9143)\t acc 91.250 (92.072)\n",
      "Test\t  accuracy: 83.480 (Err: 1.442 )\n",
      "\n",
      "Epoch: [44]\t Loss 1.0512 (0.8971)\t acc 87.500 (92.174)\n",
      "Test\t  accuracy: 83.320 (Err: 1.396 )\n",
      "\n",
      "Epoch: [45]\t Loss 1.0949 (0.8952)\t acc 88.750 (92.328)\n",
      "Test\t  accuracy: 83.660 (Err: 1.407 )\n",
      "\n",
      "Epoch: [46]\t Loss 1.0400 (0.8934)\t acc 88.750 (92.316)\n",
      "Test\t  accuracy: 83.380 (Err: 1.398 )\n",
      "\n",
      "Epoch: [47]\t Loss 0.9575 (0.8737)\t acc 93.750 (92.774)\n",
      "Test\t  accuracy: 83.560 (Err: 1.372 )\n",
      "\n",
      "Epoch: [48]\t Loss 0.8678 (0.8835)\t acc 93.750 (92.514)\n",
      "Test\t  accuracy: 82.540 (Err: 1.413 )\n",
      "\n",
      "Epoch: [49]\t Loss 0.8768 (0.8866)\t acc 96.250 (92.426)\n",
      "Test\t  accuracy: 83.570 (Err: 1.415 )\n",
      "\n",
      "Epoch: [50]\t Loss 1.0048 (0.8655)\t acc 90.000 (92.786)\n",
      "Test\t  accuracy: 83.780 (Err: 1.398 )\n",
      "\n",
      "Epoch: [51]\t Loss 0.8777 (0.8728)\t acc 93.750 (92.662)\n",
      "Test\t  accuracy: 83.410 (Err: 1.431 )\n",
      "\n",
      "Epoch: [52]\t Loss 1.0466 (0.8604)\t acc 86.250 (93.116)\n",
      "Test\t  accuracy: 82.690 (Err: 1.495 )\n",
      "\n",
      "Epoch: [53]\t Loss 0.7898 (0.8574)\t acc 98.750 (92.896)\n",
      "Test\t  accuracy: 83.320 (Err: 1.492 )\n",
      "\n",
      "Epoch: [54]\t Loss 0.9886 (0.8475)\t acc 88.750 (93.106)\n",
      "Test\t  accuracy: 82.470 (Err: 1.489 )\n",
      "\n",
      "Epoch: [55]\t Loss 0.7961 (0.8497)\t acc 96.250 (93.024)\n",
      "Test\t  accuracy: 83.280 (Err: 1.422 )\n",
      "\n",
      "Epoch: [56]\t Loss 0.9973 (0.8425)\t acc 91.250 (93.328)\n",
      "Test\t  accuracy: 83.040 (Err: 1.433 )\n",
      "\n",
      "Epoch: [57]\t Loss 0.8944 (0.8493)\t acc 92.500 (93.128)\n",
      "Test\t  accuracy: 82.610 (Err: 1.469 )\n",
      "\n",
      "Epoch: [58]\t Loss 1.0464 (0.8346)\t acc 87.500 (93.316)\n",
      "Test\t  accuracy: 83.260 (Err: 1.437 )\n",
      "\n",
      "Epoch: [59]\t Loss 0.9034 (0.8201)\t acc 91.250 (93.680)\n",
      "Test\t  accuracy: 83.510 (Err: 1.496 )\n",
      "\n",
      "Epoch: [60]\t Loss 1.0286 (0.8354)\t acc 92.500 (93.466)\n",
      "Test\t  accuracy: 82.940 (Err: 1.455 )\n",
      "\n",
      "Epoch: [61]\t Loss 0.7347 (0.8250)\t acc 95.000 (93.518)\n",
      "Test\t  accuracy: 82.750 (Err: 1.484 )\n",
      "\n",
      "Epoch: [62]\t Loss 1.0639 (0.8245)\t acc 88.750 (93.734)\n",
      "Test\t  accuracy: 83.190 (Err: 1.429 )\n",
      "\n",
      "Epoch: [63]\t Loss 1.0022 (0.8114)\t acc 93.750 (93.842)\n",
      "Test\t  accuracy: 82.710 (Err: 1.430 )\n",
      "\n",
      "Epoch: [64]\t Loss 0.8635 (0.8040)\t acc 93.750 (93.872)\n",
      "Test\t  accuracy: 82.430 (Err: 1.449 )\n",
      "\n",
      "Epoch: [65]\t Loss 0.9492 (0.7992)\t acc 95.000 (93.906)\n",
      "Test\t  accuracy: 83.050 (Err: 1.482 )\n",
      "\n",
      "Epoch: [66]\t Loss 1.0007 (0.8005)\t acc 95.000 (93.880)\n",
      "Test\t  accuracy: 83.460 (Err: 1.458 )\n",
      "\n",
      "Epoch: [67]\t Loss 0.8580 (0.8026)\t acc 91.250 (93.948)\n",
      "Test\t  accuracy: 82.950 (Err: 1.488 )\n",
      "\n",
      "Epoch: [68]\t Loss 0.9308 (0.7899)\t acc 88.750 (94.172)\n",
      "Test\t  accuracy: 83.170 (Err: 1.476 )\n",
      "\n",
      "Epoch: [69]\t Loss 0.6624 (0.7864)\t acc 93.750 (94.116)\n",
      "Test\t  accuracy: 82.490 (Err: 1.512 )\n",
      "\n",
      "Epoch: [70]\t Loss 0.8669 (0.7918)\t acc 96.250 (94.136)\n",
      "Test\t  accuracy: 82.670 (Err: 1.513 )\n",
      "\n",
      "Epoch: [71]\t Loss 0.8893 (0.7823)\t acc 96.250 (94.094)\n",
      "Test\t  accuracy: 82.280 (Err: 1.510 )\n",
      "\n",
      "Epoch: [72]\t Loss 0.8452 (0.7859)\t acc 93.750 (94.246)\n",
      "Test\t  accuracy: 82.460 (Err: 1.509 )\n",
      "\n",
      "Epoch: [73]\t Loss 0.8871 (0.7732)\t acc 91.250 (94.402)\n",
      "Test\t  accuracy: 82.660 (Err: 1.486 )\n",
      "\n",
      "Epoch: [74]\t Loss 0.9917 (0.7815)\t acc 91.250 (94.354)\n",
      "Test\t  accuracy: 82.920 (Err: 1.457 )\n",
      "\n",
      "Epoch: [75]\t Loss 1.0855 (0.7682)\t acc 90.000 (94.558)\n",
      "Test\t  accuracy: 82.500 (Err: 1.514 )\n",
      "\n",
      "Epoch: [76]\t Loss 0.7578 (0.7593)\t acc 92.500 (94.628)\n",
      "Test\t  accuracy: 82.740 (Err: 1.514 )\n",
      "\n",
      "Epoch: [77]\t Loss 0.8834 (0.7611)\t acc 90.000 (94.454)\n",
      "Test\t  accuracy: 81.060 (Err: 1.627 )\n",
      "\n",
      "Epoch: [78]\t Loss 0.5538 (0.7624)\t acc 100.000 (94.552)\n",
      "Test\t  accuracy: 81.380 (Err: 1.560 )\n",
      "\n",
      "Epoch: [79]\t Loss 0.9028 (0.7612)\t acc 91.250 (94.602)\n",
      "Test\t  accuracy: 82.310 (Err: 1.527 )\n",
      "\n",
      "Epoch: [80]\t Loss 0.8541 (0.7534)\t acc 92.500 (94.586)\n",
      "Test\t  accuracy: 82.310 (Err: 1.590 )\n",
      "\n",
      "Epoch: [81]\t Loss 0.8512 (0.7543)\t acc 93.750 (94.528)\n",
      "Test\t  accuracy: 82.430 (Err: 1.508 )\n",
      "\n",
      "Epoch: [82]\t Loss 0.7390 (0.7503)\t acc 92.500 (94.636)\n",
      "Test\t  accuracy: 82.710 (Err: 1.497 )\n",
      "\n",
      "Epoch: [83]\t Loss 0.5720 (0.7499)\t acc 98.750 (94.682)\n",
      "Test\t  accuracy: 83.020 (Err: 1.541 )\n",
      "\n",
      "Epoch: [84]\t Loss 0.7025 (0.7438)\t acc 97.500 (94.752)\n",
      "Test\t  accuracy: 82.430 (Err: 1.538 )\n",
      "\n",
      "Epoch: [85]\t Loss 0.7047 (0.7426)\t acc 95.000 (94.732)\n",
      "Test\t  accuracy: 82.710 (Err: 1.522 )\n",
      "\n",
      "Epoch: [86]\t Loss 0.8452 (0.7352)\t acc 97.500 (94.900)\n",
      "Test\t  accuracy: 81.950 (Err: 1.614 )\n",
      "\n",
      "Epoch: [87]\t Loss 0.6412 (0.7397)\t acc 97.500 (95.012)\n",
      "Test\t  accuracy: 82.430 (Err: 1.632 )\n",
      "\n",
      "Epoch: [88]\t Loss 0.8186 (0.7313)\t acc 92.500 (95.004)\n",
      "Test\t  accuracy: 82.730 (Err: 1.569 )\n",
      "\n",
      "Epoch: [89]\t Loss 0.7992 (0.7295)\t acc 96.250 (94.894)\n",
      "Test\t  accuracy: 82.750 (Err: 1.486 )\n",
      "\n",
      "Epoch: [90]\t Loss 0.6591 (0.7216)\t acc 96.250 (95.020)\n",
      "Test\t  accuracy: 82.040 (Err: 1.620 )\n",
      "\n",
      "Epoch: [91]\t Loss 0.8693 (0.7131)\t acc 92.500 (95.124)\n",
      "Test\t  accuracy: 81.990 (Err: 1.600 )\n",
      "\n",
      "Epoch: [92]\t Loss 0.6242 (0.7185)\t acc 98.750 (95.084)\n",
      "Test\t  accuracy: 83.190 (Err: 1.549 )\n",
      "\n",
      "Epoch: [93]\t Loss 0.8466 (0.7220)\t acc 95.000 (94.978)\n",
      "Test\t  accuracy: 82.690 (Err: 1.647 )\n",
      "\n",
      "Epoch: [94]\t Loss 0.7208 (0.7218)\t acc 90.000 (95.194)\n",
      "Test\t  accuracy: 81.930 (Err: 1.539 )\n",
      "\n",
      "Epoch: [95]\t Loss 0.6979 (0.7136)\t acc 97.500 (95.216)\n",
      "Test\t  accuracy: 82.650 (Err: 1.630 )\n",
      "\n",
      "Epoch: [96]\t Loss 0.6319 (0.7123)\t acc 95.000 (95.024)\n",
      "Test\t  accuracy: 82.700 (Err: 1.594 )\n",
      "\n",
      "Epoch: [97]\t Loss 0.7989 (0.7051)\t acc 93.750 (95.410)\n",
      "Test\t  accuracy: 82.000 (Err: 1.626 )\n",
      "\n",
      "Epoch: [98]\t Loss 0.8451 (0.7046)\t acc 90.000 (95.454)\n",
      "Test\t  accuracy: 82.370 (Err: 1.549 )\n",
      "\n",
      "Epoch: [99]\t Loss 0.9308 (0.7053)\t acc 91.250 (95.416)\n",
      "Test\t  accuracy: 83.630 (Err: 1.532 )\n",
      "\n",
      "Epoch: [100]\t Loss 0.6010 (0.6976)\t acc 95.000 (95.416)\n",
      "Test\t  accuracy: 82.320 (Err: 1.654 )\n",
      "\n",
      "Epoch: [101]\t Loss 0.5755 (0.7021)\t acc 97.500 (95.302)\n",
      "Test\t  accuracy: 82.700 (Err: 1.533 )\n",
      "\n",
      "Epoch: [102]\t Loss 0.6177 (0.6889)\t acc 98.750 (95.662)\n",
      "Test\t  accuracy: 82.770 (Err: 1.611 )\n",
      "\n",
      "Epoch: [103]\t Loss 0.6458 (0.6959)\t acc 96.250 (95.506)\n",
      "Test\t  accuracy: 82.270 (Err: 1.588 )\n",
      "\n",
      "Epoch: [104]\t Loss 0.6265 (0.6866)\t acc 97.500 (95.628)\n",
      "Test\t  accuracy: 82.710 (Err: 1.576 )\n",
      "\n",
      "Epoch: [105]\t Loss 0.7907 (0.6962)\t acc 93.750 (95.446)\n",
      "Test\t  accuracy: 82.670 (Err: 1.548 )\n",
      "\n",
      "Epoch: [106]\t Loss 0.6858 (0.6990)\t acc 96.250 (95.522)\n",
      "Test\t  accuracy: 82.170 (Err: 1.550 )\n",
      "\n",
      "Epoch: [107]\t Loss 0.7978 (0.6831)\t acc 96.250 (95.568)\n",
      "Test\t  accuracy: 83.040 (Err: 1.547 )\n",
      "\n",
      "Epoch: [108]\t Loss 0.8568 (0.6847)\t acc 92.500 (95.606)\n",
      "Test\t  accuracy: 82.130 (Err: 1.610 )\n",
      "\n",
      "Epoch: [109]\t Loss 0.5838 (0.6791)\t acc 96.250 (95.750)\n",
      "Test\t  accuracy: 82.020 (Err: 1.710 )\n",
      "\n",
      "Epoch: [110]\t Loss 0.8695 (0.6699)\t acc 97.500 (95.694)\n",
      "Test\t  accuracy: 83.560 (Err: 1.502 )\n",
      "\n",
      "Epoch: [111]\t Loss 0.7100 (0.6820)\t acc 93.750 (95.722)\n",
      "Test\t  accuracy: 81.500 (Err: 1.637 )\n",
      "\n",
      "Epoch: [112]\t Loss 0.6316 (0.6791)\t acc 93.750 (95.608)\n",
      "Test\t  accuracy: 82.180 (Err: 1.587 )\n",
      "\n",
      "Epoch: [113]\t Loss 0.6149 (0.6756)\t acc 97.500 (95.562)\n",
      "Test\t  accuracy: 81.570 (Err: 1.714 )\n",
      "\n",
      "Epoch: [114]\t Loss 0.6639 (0.6749)\t acc 96.250 (95.836)\n",
      "Test\t  accuracy: 81.950 (Err: 1.656 )\n",
      "\n",
      "Epoch: [115]\t Loss 0.6427 (0.6750)\t acc 96.250 (95.666)\n",
      "Test\t  accuracy: 81.910 (Err: 1.653 )\n",
      "\n",
      "Epoch: [116]\t Loss 0.7106 (0.6757)\t acc 95.000 (95.774)\n",
      "Test\t  accuracy: 82.500 (Err: 1.572 )\n",
      "\n",
      "Epoch: [117]\t Loss 0.7871 (0.6567)\t acc 92.500 (95.932)\n",
      "Test\t  accuracy: 82.080 (Err: 1.617 )\n",
      "\n",
      "Epoch: [118]\t Loss 0.7834 (0.6716)\t acc 95.000 (95.752)\n",
      "Test\t  accuracy: 81.630 (Err: 1.694 )\n",
      "\n",
      "Epoch: [119]\t Loss 0.7873 (0.6647)\t acc 92.500 (95.916)\n",
      "Test\t  accuracy: 82.740 (Err: 1.589 )\n",
      "\n",
      "Epoch: [120]\t Loss 0.6770 (0.6694)\t acc 96.250 (95.708)\n",
      "Test\t  accuracy: 80.640 (Err: 1.694 )\n",
      "\n",
      "Epoch: [121]\t Loss 0.8192 (0.6711)\t acc 88.750 (95.712)\n",
      "Test\t  accuracy: 82.670 (Err: 1.624 )\n",
      "\n",
      "Epoch: [122]\t Loss 0.5070 (0.6548)\t acc 98.750 (95.940)\n",
      "Test\t  accuracy: 82.370 (Err: 1.616 )\n",
      "\n",
      "Epoch: [123]\t Loss 0.5950 (0.6605)\t acc 98.750 (95.916)\n",
      "Test\t  accuracy: 81.700 (Err: 1.670 )\n",
      "\n",
      "Epoch: [124]\t Loss 0.5484 (0.6630)\t acc 98.750 (95.888)\n",
      "Test\t  accuracy: 82.290 (Err: 1.692 )\n",
      "\n",
      "Epoch: [125]\t Loss 0.7430 (0.6580)\t acc 92.500 (95.892)\n",
      "Test\t  accuracy: 82.620 (Err: 1.607 )\n",
      "\n",
      "Epoch: [126]\t Loss 0.6774 (0.6498)\t acc 95.000 (96.166)\n",
      "Test\t  accuracy: 81.670 (Err: 1.708 )\n",
      "\n",
      "Epoch: [127]\t Loss 0.6667 (0.6552)\t acc 97.500 (96.014)\n",
      "Test\t  accuracy: 82.690 (Err: 1.642 )\n",
      "\n",
      "Epoch: [128]\t Loss 0.4409 (0.6465)\t acc 97.500 (96.122)\n",
      "Test\t  accuracy: 81.220 (Err: 1.743 )\n",
      "\n",
      "Epoch: [129]\t Loss 0.8074 (0.6593)\t acc 96.250 (95.952)\n",
      "Test\t  accuracy: 81.530 (Err: 1.685 )\n",
      "\n",
      "Epoch: [130]\t Loss 0.7799 (0.6530)\t acc 92.500 (95.982)\n",
      "Test\t  accuracy: 83.100 (Err: 1.616 )\n",
      "\n",
      "Epoch: [131]\t Loss 0.5509 (0.6541)\t acc 98.750 (96.046)\n",
      "Test\t  accuracy: 82.940 (Err: 1.611 )\n",
      "\n",
      "Epoch: [132]\t Loss 0.5345 (0.6384)\t acc 100.000 (96.272)\n",
      "Test\t  accuracy: 81.660 (Err: 1.725 )\n",
      "\n",
      "Epoch: [133]\t Loss 0.8876 (0.6381)\t acc 92.500 (96.284)\n",
      "Test\t  accuracy: 82.620 (Err: 1.652 )\n",
      "\n",
      "Epoch: [134]\t Loss 0.7852 (0.6475)\t acc 93.750 (96.150)\n",
      "Test\t  accuracy: 82.740 (Err: 1.606 )\n",
      "\n",
      "Epoch: [135]\t Loss 0.8676 (0.6374)\t acc 92.500 (96.248)\n",
      "Test\t  accuracy: 82.780 (Err: 1.676 )\n",
      "\n",
      "Epoch: [136]\t Loss 0.6513 (0.6306)\t acc 93.750 (96.348)\n",
      "Test\t  accuracy: 81.480 (Err: 1.723 )\n",
      "\n",
      "Epoch: [137]\t Loss 0.7657 (0.6470)\t acc 98.750 (96.150)\n",
      "Test\t  accuracy: 82.480 (Err: 1.635 )\n",
      "\n",
      "Epoch: [138]\t Loss 0.5879 (0.6478)\t acc 97.500 (96.120)\n",
      "Test\t  accuracy: 81.780 (Err: 1.655 )\n",
      "\n",
      "Epoch: [139]\t Loss 0.7365 (0.6337)\t acc 95.000 (96.166)\n",
      "Test\t  accuracy: 82.640 (Err: 1.622 )\n",
      "\n",
      "Epoch: [140]\t Loss 0.7456 (0.6273)\t acc 91.250 (96.234)\n",
      "Test\t  accuracy: 81.710 (Err: 1.751 )\n",
      "\n",
      "Epoch: [141]\t Loss 0.7202 (0.6477)\t acc 95.000 (96.044)\n",
      "Test\t  accuracy: 82.040 (Err: 1.634 )\n",
      "\n",
      "Epoch: [142]\t Loss 0.6860 (0.6442)\t acc 97.500 (96.152)\n",
      "Test\t  accuracy: 82.240 (Err: 1.672 )\n",
      "\n",
      "Epoch: [143]\t Loss 0.4910 (0.6252)\t acc 98.750 (96.332)\n",
      "Test\t  accuracy: 80.730 (Err: 1.672 )\n",
      "\n",
      "Epoch: [144]\t Loss 0.5981 (0.6340)\t acc 97.500 (96.248)\n",
      "Test\t  accuracy: 82.170 (Err: 1.629 )\n",
      "\n",
      "Epoch: [145]\t Loss 0.8273 (0.6410)\t acc 93.750 (96.096)\n",
      "Test\t  accuracy: 81.620 (Err: 1.700 )\n",
      "\n",
      "Epoch: [146]\t Loss 0.7403 (0.6205)\t acc 95.000 (96.348)\n",
      "Test\t  accuracy: 82.440 (Err: 1.656 )\n",
      "\n",
      "Epoch: [147]\t Loss 0.6026 (0.6194)\t acc 96.250 (96.466)\n",
      "Test\t  accuracy: 82.400 (Err: 1.718 )\n",
      "\n",
      "Epoch: [148]\t Loss 0.4917 (0.6340)\t acc 98.750 (96.252)\n",
      "Test\t  accuracy: 81.710 (Err: 1.715 )\n",
      "\n",
      "Epoch: [149]\t Loss 0.7609 (0.6202)\t acc 96.250 (96.354)\n",
      "Test\t  accuracy: 81.880 (Err: 1.702 )\n",
      "\n",
      "Epoch: [150]\t Loss 0.8121 (0.6249)\t acc 96.250 (96.390)\n",
      "Test\t  accuracy: 82.060 (Err: 1.643 )\n",
      "\n",
      "Epoch: [151]\t Loss 0.5851 (0.6171)\t acc 98.750 (96.350)\n",
      "Test\t  accuracy: 82.010 (Err: 1.733 )\n",
      "\n",
      "Epoch: [152]\t Loss 0.4936 (0.6183)\t acc 98.750 (96.410)\n",
      "Test\t  accuracy: 82.580 (Err: 1.605 )\n",
      "\n",
      "Epoch: [153]\t Loss 0.4793 (0.6130)\t acc 97.500 (96.388)\n",
      "Test\t  accuracy: 81.820 (Err: 1.744 )\n",
      "\n",
      "Epoch: [154]\t Loss 0.4618 (0.6191)\t acc 97.500 (96.430)\n",
      "Test\t  accuracy: 81.650 (Err: 1.683 )\n",
      "\n",
      "Epoch: [155]\t Loss 0.5747 (0.6234)\t acc 96.250 (96.356)\n",
      "Test\t  accuracy: 80.560 (Err: 1.720 )\n",
      "\n",
      "Epoch: [156]\t Loss 0.7497 (0.6171)\t acc 96.250 (96.514)\n",
      "Test\t  accuracy: 82.250 (Err: 1.602 )\n",
      "\n",
      "Epoch: [157]\t Loss 0.6407 (0.6125)\t acc 97.500 (96.456)\n",
      "Test\t  accuracy: 81.330 (Err: 1.639 )\n",
      "\n",
      "Epoch: [158]\t Loss 0.6098 (0.6164)\t acc 95.000 (96.362)\n",
      "Test\t  accuracy: 82.590 (Err: 1.648 )\n",
      "\n",
      "Epoch: [159]\t Loss 0.7470 (0.6189)\t acc 93.750 (96.382)\n",
      "Test\t  accuracy: 81.250 (Err: 1.760 )\n",
      "\n",
      "Epoch: [160]\t Loss 0.7553 (0.6025)\t acc 95.000 (96.542)\n",
      "Test\t  accuracy: 81.340 (Err: 1.839 )\n",
      "\n",
      "Epoch: [161]\t Loss 0.7555 (0.6139)\t acc 91.250 (96.500)\n",
      "Test\t  accuracy: 81.820 (Err: 1.641 )\n",
      "\n",
      "Epoch: [162]\t Loss 0.7212 (0.6191)\t acc 95.000 (96.418)\n",
      "Test\t  accuracy: 82.450 (Err: 1.626 )\n",
      "\n",
      "Epoch: [163]\t Loss 0.7778 (0.6153)\t acc 93.750 (96.368)\n",
      "Test\t  accuracy: 82.020 (Err: 1.667 )\n",
      "\n",
      "Epoch: [164]\t Loss 0.8213 (0.6059)\t acc 90.000 (96.570)\n",
      "Test\t  accuracy: 82.780 (Err: 1.606 )\n",
      "\n",
      "Epoch: [165]\t Loss 0.7090 (0.5994)\t acc 98.750 (96.612)\n",
      "Test\t  accuracy: 81.240 (Err: 1.809 )\n",
      "\n",
      "Epoch: [166]\t Loss 0.5550 (0.6132)\t acc 100.000 (96.438)\n",
      "Test\t  accuracy: 82.430 (Err: 1.676 )\n",
      "\n",
      "Epoch: [167]\t Loss 0.7338 (0.6021)\t acc 96.250 (96.584)\n",
      "Test\t  accuracy: 82.320 (Err: 1.624 )\n",
      "\n",
      "Epoch: [168]\t Loss 0.5494 (0.6052)\t acc 96.250 (96.556)\n",
      "Test\t  accuracy: 82.870 (Err: 1.600 )\n",
      "\n",
      "Epoch: [169]\t Loss 0.5668 (0.5965)\t acc 95.000 (96.630)\n",
      "Test\t  accuracy: 82.170 (Err: 1.729 )\n",
      "\n",
      "Epoch: [170]\t Loss 0.5015 (0.5952)\t acc 97.500 (96.602)\n",
      "Test\t  accuracy: 82.460 (Err: 1.699 )\n",
      "\n",
      "Epoch: [171]\t Loss 0.6460 (0.5875)\t acc 97.500 (96.798)\n",
      "Test\t  accuracy: 81.760 (Err: 1.757 )\n",
      "\n",
      "Epoch: [172]\t Loss 0.6348 (0.5875)\t acc 97.500 (96.784)\n",
      "Test\t  accuracy: 82.350 (Err: 1.638 )\n",
      "\n",
      "Epoch: [173]\t Loss 0.6871 (0.6005)\t acc 95.000 (96.582)\n",
      "Test\t  accuracy: 82.090 (Err: 1.633 )\n",
      "\n",
      "Epoch: [174]\t Loss 0.7958 (0.5986)\t acc 95.000 (96.620)\n",
      "Test\t  accuracy: 82.500 (Err: 1.624 )\n",
      "\n",
      "Epoch: [175]\t Loss 0.6117 (0.5967)\t acc 93.750 (96.630)\n",
      "Test\t  accuracy: 81.890 (Err: 1.710 )\n",
      "\n",
      "Epoch: [176]\t Loss 0.4604 (0.5947)\t acc 100.000 (96.618)\n",
      "Test\t  accuracy: 81.580 (Err: 1.715 )\n",
      "\n",
      "Epoch: [177]\t Loss 0.7850 (0.5948)\t acc 96.250 (96.608)\n",
      "Test\t  accuracy: 82.430 (Err: 1.672 )\n",
      "\n",
      "Epoch: [178]\t Loss 0.6004 (0.5919)\t acc 96.250 (96.702)\n",
      "Test\t  accuracy: 82.040 (Err: 1.705 )\n",
      "\n",
      "Epoch: [179]\t Loss 0.5751 (0.6031)\t acc 96.250 (96.664)\n",
      "Test\t  accuracy: 81.890 (Err: 1.801 )\n",
      "\n",
      "Epoch: [180]\t Loss 0.6316 (0.5915)\t acc 96.250 (96.752)\n",
      "Test\t  accuracy: 81.910 (Err: 1.687 )\n",
      "\n",
      "Epoch: [181]\t Loss 0.5091 (0.5923)\t acc 97.500 (96.720)\n",
      "Test\t  accuracy: 81.530 (Err: 1.786 )\n",
      "\n",
      "Epoch: [182]\t Loss 0.7208 (0.5930)\t acc 95.000 (96.650)\n",
      "Test\t  accuracy: 81.800 (Err: 1.671 )\n",
      "\n",
      "Epoch: [183]\t Loss 0.5811 (0.6019)\t acc 96.250 (96.734)\n",
      "Test\t  accuracy: 81.990 (Err: 1.689 )\n",
      "\n",
      "Epoch: [184]\t Loss 0.6294 (0.5920)\t acc 96.250 (96.648)\n",
      "Test\t  accuracy: 82.830 (Err: 1.642 )\n",
      "\n",
      "Epoch: [185]\t Loss 0.6096 (0.5794)\t acc 97.500 (96.762)\n",
      "Test\t  accuracy: 82.490 (Err: 1.691 )\n",
      "\n",
      "Epoch: [186]\t Loss 0.5491 (0.5786)\t acc 97.500 (96.884)\n",
      "Test\t  accuracy: 82.060 (Err: 1.689 )\n",
      "\n",
      "Epoch: [187]\t Loss 0.6991 (0.5833)\t acc 93.750 (96.794)\n",
      "Test\t  accuracy: 82.310 (Err: 1.626 )\n",
      "\n",
      "Epoch: [188]\t Loss 0.6492 (0.5889)\t acc 91.250 (96.666)\n",
      "Test\t  accuracy: 82.160 (Err: 1.700 )\n",
      "\n",
      "Epoch: [189]\t Loss 0.7730 (0.5894)\t acc 93.750 (96.798)\n",
      "Test\t  accuracy: 82.450 (Err: 1.710 )\n",
      "\n",
      "Epoch: [190]\t Loss 0.5327 (0.5920)\t acc 97.500 (96.722)\n",
      "Test\t  accuracy: 81.930 (Err: 1.749 )\n",
      "\n",
      "Epoch: [191]\t Loss 0.5999 (0.5899)\t acc 93.750 (96.820)\n",
      "Test\t  accuracy: 82.050 (Err: 1.699 )\n",
      "\n",
      "Epoch: [192]\t Loss 0.7842 (0.5771)\t acc 92.500 (96.820)\n",
      "Test\t  accuracy: 82.100 (Err: 1.718 )\n",
      "\n",
      "Epoch: [193]\t Loss 0.7584 (0.5761)\t acc 98.750 (96.926)\n",
      "Test\t  accuracy: 81.860 (Err: 1.686 )\n",
      "\n",
      "Epoch: [194]\t Loss 0.5706 (0.5677)\t acc 97.500 (96.978)\n",
      "Test\t  accuracy: 82.310 (Err: 1.735 )\n",
      "\n",
      "Epoch: [195]\t Loss 0.4933 (0.5619)\t acc 100.000 (97.002)\n",
      "Test\t  accuracy: 81.780 (Err: 1.752 )\n",
      "\n",
      "Epoch: [196]\t Loss 0.6223 (0.5785)\t acc 98.750 (96.870)\n",
      "Test\t  accuracy: 81.260 (Err: 1.663 )\n",
      "\n",
      "Epoch: [197]\t Loss 0.6640 (0.5778)\t acc 96.250 (96.878)\n",
      "Test\t  accuracy: 80.650 (Err: 1.750 )\n",
      "\n",
      "Epoch: [198]\t Loss 0.5946 (0.5744)\t acc 100.000 (96.916)\n",
      "Test\t  accuracy: 82.650 (Err: 1.705 )\n",
      "\n",
      "Epoch: [199]\t Loss 0.8003 (0.5723)\t acc 96.250 (96.900)\n",
      "Test\t  accuracy: 81.990 (Err: 1.733 )\n",
      "\n",
      "Epoch: [200]\t Loss 0.7221 (0.5800)\t acc 96.250 (96.856)\n",
      "Test\t  accuracy: 82.530 (Err: 1.656 )\n",
      "\n",
      "Epoch: [201]\t Loss 0.7604 (0.5715)\t acc 92.500 (96.894)\n",
      "Test\t  accuracy: 82.690 (Err: 1.686 )\n",
      "\n",
      "Epoch: [202]\t Loss 0.5153 (0.5824)\t acc 97.500 (96.964)\n",
      "Test\t  accuracy: 82.910 (Err: 1.571 )\n",
      "\n",
      "Epoch: [203]\t Loss 0.5396 (0.5727)\t acc 98.750 (96.890)\n",
      "Test\t  accuracy: 81.380 (Err: 1.750 )\n",
      "\n",
      "Epoch: [204]\t Loss 0.7778 (0.5769)\t acc 93.750 (96.894)\n",
      "Test\t  accuracy: 82.000 (Err: 1.672 )\n",
      "\n",
      "Epoch: [205]\t Loss 0.4709 (0.5717)\t acc 95.000 (96.984)\n",
      "Test\t  accuracy: 82.840 (Err: 1.714 )\n",
      "\n",
      "Epoch: [206]\t Loss 0.7145 (0.5721)\t acc 96.250 (96.994)\n",
      "Test\t  accuracy: 82.360 (Err: 1.699 )\n",
      "\n",
      "Epoch: [207]\t Loss 0.5061 (0.5767)\t acc 97.500 (96.826)\n",
      "Test\t  accuracy: 82.160 (Err: 1.684 )\n",
      "\n",
      "Epoch: [208]\t Loss 0.5494 (0.5726)\t acc 96.250 (96.920)\n",
      "Test\t  accuracy: 81.540 (Err: 1.779 )\n",
      "\n",
      "Epoch: [209]\t Loss 0.7246 (0.5648)\t acc 96.250 (97.028)\n",
      "Test\t  accuracy: 81.420 (Err: 1.775 )\n",
      "\n",
      "Epoch: [210]\t Loss 0.5263 (0.5671)\t acc 98.750 (97.054)\n",
      "Test\t  accuracy: 81.180 (Err: 1.682 )\n",
      "\n",
      "Epoch: [211]\t Loss 0.5808 (0.5661)\t acc 98.750 (96.972)\n",
      "Test\t  accuracy: 82.460 (Err: 1.676 )\n",
      "\n",
      "Epoch: [212]\t Loss 0.5729 (0.5701)\t acc 95.000 (96.988)\n",
      "Test\t  accuracy: 80.950 (Err: 1.809 )\n",
      "\n",
      "Epoch: [213]\t Loss 0.4548 (0.5657)\t acc 98.750 (96.946)\n",
      "Test\t  accuracy: 81.840 (Err: 1.672 )\n",
      "\n",
      "Epoch: [214]\t Loss 0.7041 (0.5690)\t acc 97.500 (96.986)\n",
      "Test\t  accuracy: 81.880 (Err: 1.740 )\n",
      "\n",
      "Epoch: [215]\t Loss 0.6717 (0.5808)\t acc 92.500 (96.914)\n",
      "Test\t  accuracy: 82.830 (Err: 1.651 )\n",
      "\n",
      "Epoch: [216]\t Loss 0.4975 (0.5632)\t acc 97.500 (97.060)\n",
      "Test\t  accuracy: 81.810 (Err: 1.765 )\n",
      "\n",
      "Epoch: [217]\t Loss 0.3747 (0.5613)\t acc 98.750 (97.006)\n",
      "Test\t  accuracy: 81.730 (Err: 1.757 )\n",
      "\n",
      "Epoch: [218]\t Loss 0.5049 (0.5536)\t acc 97.500 (97.096)\n",
      "Test\t  accuracy: 82.020 (Err: 1.669 )\n",
      "\n",
      "Epoch: [219]\t Loss 0.3432 (0.5674)\t acc 100.000 (97.160)\n",
      "Test\t  accuracy: 82.240 (Err: 1.822 )\n",
      "\n",
      "Epoch: [220]\t Loss 0.6528 (0.5562)\t acc 95.000 (97.160)\n",
      "Test\t  accuracy: 81.660 (Err: 1.744 )\n",
      "\n",
      "Epoch: [221]\t Loss 0.6867 (0.5630)\t acc 96.250 (97.302)\n",
      "Test\t  accuracy: 82.190 (Err: 1.683 )\n",
      "\n",
      "Epoch: [222]\t Loss 0.4302 (0.5603)\t acc 97.500 (97.046)\n",
      "Test\t  accuracy: 81.170 (Err: 1.846 )\n",
      "\n",
      "Epoch: [223]\t Loss 0.7124 (0.5660)\t acc 93.750 (96.966)\n",
      "Test\t  accuracy: 82.060 (Err: 1.676 )\n",
      "\n",
      "Epoch: [224]\t Loss 0.6359 (0.5580)\t acc 93.750 (97.120)\n",
      "Test\t  accuracy: 81.840 (Err: 1.723 )\n",
      "\n",
      "Epoch: [225]\t Loss 0.8296 (0.5582)\t acc 96.250 (97.066)\n",
      "Test\t  accuracy: 82.560 (Err: 1.640 )\n",
      "\n",
      "Epoch: [226]\t Loss 0.6012 (0.5569)\t acc 100.000 (97.130)\n",
      "Test\t  accuracy: 81.890 (Err: 1.673 )\n",
      "\n",
      "Epoch: [227]\t Loss 0.5313 (0.5588)\t acc 96.250 (97.038)\n",
      "Test\t  accuracy: 81.640 (Err: 1.786 )\n",
      "\n",
      "Epoch: [228]\t Loss 0.5339 (0.5547)\t acc 97.500 (97.044)\n",
      "Test\t  accuracy: 82.140 (Err: 1.725 )\n",
      "\n",
      "Epoch: [229]\t Loss 0.6958 (0.5545)\t acc 95.000 (97.096)\n",
      "Test\t  accuracy: 81.820 (Err: 1.693 )\n",
      "\n",
      "Epoch: [230]\t Loss 0.6570 (0.5489)\t acc 93.750 (97.110)\n",
      "Test\t  accuracy: 82.240 (Err: 1.706 )\n",
      "\n",
      "Epoch: [231]\t Loss 0.4524 (0.5633)\t acc 98.750 (97.060)\n",
      "Test\t  accuracy: 81.630 (Err: 1.708 )\n",
      "\n",
      "Epoch: [232]\t Loss 0.5559 (0.5653)\t acc 97.500 (97.198)\n",
      "Test\t  accuracy: 82.360 (Err: 1.697 )\n",
      "\n",
      "Epoch: [233]\t Loss 0.5391 (0.5455)\t acc 98.750 (97.174)\n",
      "Test\t  accuracy: 81.990 (Err: 1.712 )\n",
      "\n",
      "Epoch: [234]\t Loss 0.5661 (0.5531)\t acc 96.250 (97.184)\n",
      "Test\t  accuracy: 82.510 (Err: 1.705 )\n",
      "\n",
      "Epoch: [235]\t Loss 0.6548 (0.5507)\t acc 97.500 (97.226)\n",
      "Test\t  accuracy: 81.910 (Err: 1.660 )\n",
      "\n",
      "Epoch: [236]\t Loss 0.4472 (0.5609)\t acc 97.500 (97.074)\n",
      "Test\t  accuracy: 80.960 (Err: 1.762 )\n",
      "\n",
      "Epoch: [237]\t Loss 0.5857 (0.5475)\t acc 96.250 (97.190)\n",
      "Test\t  accuracy: 81.430 (Err: 1.793 )\n",
      "\n",
      "Epoch: [238]\t Loss 0.6902 (0.5558)\t acc 91.250 (97.094)\n",
      "Test\t  accuracy: 82.170 (Err: 1.649 )\n",
      "\n",
      "Epoch: [239]\t Loss 0.5210 (0.5549)\t acc 100.000 (97.158)\n",
      "Test\t  accuracy: 82.020 (Err: 1.727 )\n",
      "\n",
      "Epoch: [240]\t Loss 0.4683 (0.5481)\t acc 98.750 (97.132)\n",
      "Test\t  accuracy: 82.600 (Err: 1.768 )\n",
      "\n",
      "Epoch: [241]\t Loss 0.5231 (0.5427)\t acc 98.750 (97.202)\n",
      "Test\t  accuracy: 82.370 (Err: 1.761 )\n",
      "\n",
      "Epoch: [242]\t Loss 0.5138 (0.5501)\t acc 96.250 (97.202)\n",
      "Test\t  accuracy: 81.740 (Err: 1.772 )\n",
      "\n",
      "Epoch: [243]\t Loss 0.5482 (0.5525)\t acc 97.500 (97.090)\n",
      "Test\t  accuracy: 81.470 (Err: 1.786 )\n",
      "\n",
      "Epoch: [244]\t Loss 0.9563 (0.5587)\t acc 95.000 (97.086)\n",
      "Test\t  accuracy: 81.120 (Err: 1.814 )\n",
      "\n",
      "Epoch: [245]\t Loss 0.5983 (0.5512)\t acc 95.000 (97.108)\n",
      "Test\t  accuracy: 81.490 (Err: 1.676 )\n",
      "\n",
      "Epoch: [246]\t Loss 0.7586 (0.5454)\t acc 91.250 (97.204)\n",
      "Test\t  accuracy: 81.430 (Err: 1.783 )\n",
      "\n",
      "Epoch: [247]\t Loss 0.3996 (0.5594)\t acc 100.000 (97.028)\n",
      "Test\t  accuracy: 82.150 (Err: 1.763 )\n",
      "\n",
      "Epoch: [248]\t Loss 0.6591 (0.5400)\t acc 96.250 (97.088)\n",
      "Test\t  accuracy: 81.910 (Err: 1.708 )\n",
      "\n",
      "Epoch: [249]\t Loss 0.8188 (0.5571)\t acc 97.500 (97.010)\n",
      "Test\t  accuracy: 82.070 (Err: 1.633 )\n",
      "\n",
      "Epoch: [250]\t Loss 0.6624 (0.5506)\t acc 97.500 (97.160)\n",
      "Test\t  accuracy: 81.720 (Err: 1.736 )\n",
      "\n",
      "Epoch: [251]\t Loss 0.6818 (0.5401)\t acc 98.750 (97.190)\n",
      "Test\t  accuracy: 81.180 (Err: 1.801 )\n",
      "\n",
      "Epoch: [252]\t Loss 0.5576 (0.5547)\t acc 97.500 (97.064)\n",
      "Test\t  accuracy: 82.720 (Err: 1.667 )\n",
      "\n",
      "Epoch: [253]\t Loss 0.5406 (0.5330)\t acc 100.000 (97.322)\n",
      "Test\t  accuracy: 82.330 (Err: 1.726 )\n",
      "\n",
      "Epoch: [254]\t Loss 0.6977 (0.5370)\t acc 91.250 (97.434)\n",
      "Test\t  accuracy: 81.430 (Err: 1.835 )\n",
      "\n",
      "Epoch: [255]\t Loss 0.5975 (0.5496)\t acc 96.250 (97.116)\n",
      "Test\t  accuracy: 81.850 (Err: 1.827 )\n",
      "\n",
      "Epoch: [256]\t Loss 0.6158 (0.5345)\t acc 96.250 (97.286)\n",
      "Test\t  accuracy: 81.880 (Err: 1.759 )\n",
      "\n",
      "Epoch: [257]\t Loss 0.5630 (0.5365)\t acc 97.500 (97.350)\n",
      "Test\t  accuracy: 81.750 (Err: 1.835 )\n",
      "\n",
      "Epoch: [258]\t Loss 0.5702 (0.5529)\t acc 100.000 (97.168)\n",
      "Test\t  accuracy: 81.640 (Err: 1.780 )\n",
      "\n",
      "Epoch: [259]\t Loss 0.5929 (0.5361)\t acc 98.750 (97.410)\n",
      "Test\t  accuracy: 82.560 (Err: 1.766 )\n",
      "\n",
      "Epoch: [260]\t Loss 0.6200 (0.5370)\t acc 96.250 (97.274)\n",
      "Test\t  accuracy: 82.390 (Err: 1.766 )\n",
      "\n",
      "Epoch: [261]\t Loss 0.6430 (0.5469)\t acc 96.250 (97.304)\n",
      "Test\t  accuracy: 81.730 (Err: 1.772 )\n",
      "\n",
      "Epoch: [262]\t Loss 0.4785 (0.5354)\t acc 97.500 (97.276)\n",
      "Test\t  accuracy: 81.770 (Err: 1.734 )\n",
      "\n",
      "Epoch: [263]\t Loss 0.4852 (0.5320)\t acc 98.750 (97.242)\n",
      "Test\t  accuracy: 81.590 (Err: 1.733 )\n",
      "\n",
      "Epoch: [264]\t Loss 0.5447 (0.5300)\t acc 100.000 (97.348)\n",
      "Test\t  accuracy: 81.920 (Err: 1.743 )\n",
      "\n",
      "Epoch: [265]\t Loss 0.3403 (0.5412)\t acc 98.750 (97.154)\n",
      "Test\t  accuracy: 82.520 (Err: 1.787 )\n",
      "\n",
      "Epoch: [266]\t Loss 0.4042 (0.5470)\t acc 100.000 (97.136)\n",
      "Test\t  accuracy: 81.750 (Err: 1.749 )\n",
      "\n",
      "Epoch: [267]\t Loss 0.5561 (0.5295)\t acc 98.750 (97.388)\n",
      "Test\t  accuracy: 82.150 (Err: 1.792 )\n",
      "\n",
      "Epoch: [268]\t Loss 0.6450 (0.5448)\t acc 97.500 (97.208)\n",
      "Test\t  accuracy: 80.420 (Err: 1.883 )\n",
      "\n",
      "Epoch: [269]\t Loss 0.6279 (0.5276)\t acc 96.250 (97.336)\n",
      "Test\t  accuracy: 82.100 (Err: 1.738 )\n",
      "\n",
      "Epoch: [270]\t Loss 0.6195 (0.5402)\t acc 97.500 (97.314)\n",
      "Test\t  accuracy: 82.460 (Err: 1.699 )\n",
      "\n",
      "Epoch: [271]\t Loss 0.6154 (0.5400)\t acc 98.750 (97.272)\n",
      "Test\t  accuracy: 82.440 (Err: 1.759 )\n",
      "\n",
      "Epoch: [272]\t Loss 0.6766 (0.5418)\t acc 97.500 (97.196)\n",
      "Test\t  accuracy: 81.880 (Err: 1.821 )\n",
      "\n",
      "Epoch: [273]\t Loss 0.5636 (0.5393)\t acc 97.500 (97.226)\n",
      "Test\t  accuracy: 82.170 (Err: 1.717 )\n",
      "\n",
      "Epoch: [274]\t Loss 0.8065 (0.5356)\t acc 96.250 (97.346)\n",
      "Test\t  accuracy: 81.690 (Err: 1.718 )\n",
      "\n",
      "Epoch: [275]\t Loss 0.4789 (0.5306)\t acc 100.000 (97.398)\n",
      "Test\t  accuracy: 81.690 (Err: 1.893 )\n",
      "\n",
      "Epoch: [276]\t Loss 0.6495 (0.5318)\t acc 95.000 (97.352)\n",
      "Test\t  accuracy: 82.000 (Err: 1.696 )\n",
      "\n",
      "Epoch: [277]\t Loss 0.5598 (0.5429)\t acc 97.500 (97.098)\n",
      "Test\t  accuracy: 81.180 (Err: 1.846 )\n",
      "\n",
      "Epoch: [278]\t Loss 0.4910 (0.5350)\t acc 96.250 (97.274)\n",
      "Test\t  accuracy: 82.030 (Err: 1.805 )\n",
      "\n",
      "Epoch: [279]\t Loss 0.5054 (0.5333)\t acc 96.250 (97.318)\n",
      "Test\t  accuracy: 81.480 (Err: 1.844 )\n",
      "\n",
      "Epoch: [280]\t Loss 0.4830 (0.5327)\t acc 98.750 (97.316)\n",
      "Test\t  accuracy: 81.940 (Err: 1.736 )\n",
      "\n",
      "Epoch: [281]\t Loss 0.4903 (0.5290)\t acc 97.500 (97.384)\n",
      "Test\t  accuracy: 82.070 (Err: 1.692 )\n",
      "\n",
      "Epoch: [282]\t Loss 0.7065 (0.5309)\t acc 93.750 (97.364)\n",
      "Test\t  accuracy: 82.230 (Err: 1.648 )\n",
      "\n",
      "Epoch: [283]\t Loss 0.3673 (0.5294)\t acc 100.000 (97.312)\n",
      "Test\t  accuracy: 81.240 (Err: 1.832 )\n",
      "\n",
      "Epoch: [284]\t Loss 0.6120 (0.5279)\t acc 100.000 (97.420)\n",
      "Test\t  accuracy: 82.320 (Err: 1.716 )\n",
      "\n",
      "Epoch: [285]\t Loss 0.5338 (0.5325)\t acc 98.750 (97.324)\n",
      "Test\t  accuracy: 82.050 (Err: 1.809 )\n",
      "\n",
      "Epoch: [286]\t Loss 0.4921 (0.5175)\t acc 97.500 (97.428)\n",
      "Test\t  accuracy: 81.860 (Err: 1.774 )\n",
      "\n",
      "Epoch: [287]\t Loss 0.5270 (0.5440)\t acc 98.750 (97.140)\n",
      "Test\t  accuracy: 80.460 (Err: 1.792 )\n",
      "\n",
      "Epoch: [288]\t Loss 0.4740 (0.5304)\t acc 96.250 (97.402)\n",
      "Test\t  accuracy: 82.190 (Err: 1.770 )\n",
      "\n",
      "Epoch: [289]\t Loss 0.8177 (0.5272)\t acc 91.250 (97.474)\n",
      "Test\t  accuracy: 82.100 (Err: 1.780 )\n",
      "\n",
      "Epoch: [290]\t Loss 0.5259 (0.5240)\t acc 97.500 (97.576)\n",
      "Test\t  accuracy: 82.040 (Err: 1.792 )\n",
      "\n",
      "Epoch: [291]\t Loss 0.5081 (0.5371)\t acc 97.500 (97.310)\n",
      "Test\t  accuracy: 81.280 (Err: 1.827 )\n",
      "\n",
      "Epoch: [292]\t Loss 0.6602 (0.5229)\t acc 96.250 (97.370)\n",
      "Test\t  accuracy: 81.390 (Err: 1.831 )\n",
      "\n",
      "Epoch: [293]\t Loss 0.4893 (0.5350)\t acc 95.000 (97.292)\n",
      "Test\t  accuracy: 81.540 (Err: 1.938 )\n",
      "\n",
      "Epoch: [294]\t Loss 0.5481 (0.5356)\t acc 100.000 (97.312)\n",
      "Test\t  accuracy: 81.510 (Err: 1.779 )\n",
      "\n",
      "Epoch: [295]\t Loss 0.5388 (0.5260)\t acc 96.250 (97.324)\n",
      "Test\t  accuracy: 81.520 (Err: 1.800 )\n",
      "\n",
      "Epoch: [296]\t Loss 0.4283 (0.5226)\t acc 100.000 (97.390)\n",
      "Test\t  accuracy: 81.520 (Err: 1.840 )\n",
      "\n",
      "Epoch: [297]\t Loss 0.5998 (0.5227)\t acc 97.500 (97.482)\n",
      "Test\t  accuracy: 81.230 (Err: 1.871 )\n",
      "\n",
      "Epoch: [298]\t Loss 0.6525 (0.5205)\t acc 97.500 (97.468)\n",
      "Test\t  accuracy: 81.360 (Err: 1.801 )\n",
      "\n",
      "Epoch: [299]\t Loss 0.6041 (0.5213)\t acc 96.250 (97.458)\n",
      "Test\t  accuracy: 81.610 (Err: 1.858 )\n",
      "\n",
      "Epoch: [300]\t Loss 0.6960 (0.5229)\t acc 95.000 (97.412)\n",
      "Test\t  accuracy: 81.780 (Err: 1.691 )\n",
      "\n",
      "Epoch: [301]\t Loss 0.5605 (0.5323)\t acc 97.500 (97.318)\n",
      "Test\t  accuracy: 82.370 (Err: 1.747 )\n",
      "\n",
      "Epoch: [302]\t Loss 0.3282 (0.5198)\t acc 100.000 (97.548)\n",
      "Test\t  accuracy: 80.900 (Err: 1.860 )\n",
      "\n",
      "Epoch: [303]\t Loss 0.5546 (0.5233)\t acc 96.250 (97.494)\n",
      "Test\t  accuracy: 80.960 (Err: 1.799 )\n",
      "\n",
      "Epoch: [304]\t Loss 0.6461 (0.5322)\t acc 98.750 (97.320)\n",
      "Test\t  accuracy: 80.280 (Err: 1.944 )\n",
      "\n",
      "Epoch: [305]\t Loss 0.7364 (0.5144)\t acc 96.250 (97.554)\n",
      "Test\t  accuracy: 80.900 (Err: 1.824 )\n",
      "\n",
      "Epoch: [306]\t Loss 0.6320 (0.5226)\t acc 98.750 (97.438)\n",
      "Test\t  accuracy: 81.460 (Err: 1.857 )\n",
      "\n",
      "Epoch: [307]\t Loss 0.4473 (0.5340)\t acc 97.500 (97.356)\n",
      "Test\t  accuracy: 81.630 (Err: 1.694 )\n",
      "\n",
      "Epoch: [308]\t Loss 0.6222 (0.5262)\t acc 100.000 (97.414)\n",
      "Test\t  accuracy: 81.110 (Err: 1.775 )\n",
      "\n",
      "Epoch: [309]\t Loss 0.7369 (0.5233)\t acc 93.750 (97.272)\n",
      "Test\t  accuracy: 81.690 (Err: 1.760 )\n",
      "\n",
      "Epoch: [310]\t Loss 0.4504 (0.5144)\t acc 97.500 (97.522)\n",
      "Test\t  accuracy: 82.730 (Err: 1.725 )\n",
      "\n",
      "Epoch: [311]\t Loss 0.5005 (0.5135)\t acc 100.000 (97.428)\n",
      "Test\t  accuracy: 82.030 (Err: 1.819 )\n",
      "\n",
      "Epoch: [312]\t Loss 0.4393 (0.5245)\t acc 98.750 (97.374)\n",
      "Test\t  accuracy: 81.420 (Err: 1.806 )\n",
      "\n",
      "Epoch: [313]\t Loss 0.3977 (0.5146)\t acc 97.500 (97.528)\n",
      "Test\t  accuracy: 81.160 (Err: 1.810 )\n",
      "\n",
      "Epoch: [314]\t Loss 0.5941 (0.5150)\t acc 98.750 (97.548)\n",
      "Test\t  accuracy: 82.210 (Err: 1.790 )\n",
      "\n",
      "Epoch: [315]\t Loss 0.5276 (0.5159)\t acc 100.000 (97.416)\n",
      "Test\t  accuracy: 81.780 (Err: 1.685 )\n",
      "\n",
      "Epoch: [316]\t Loss 0.4683 (0.5099)\t acc 98.750 (97.598)\n",
      "Test\t  accuracy: 81.890 (Err: 1.867 )\n",
      "\n",
      "Epoch: [317]\t Loss 0.6608 (0.5157)\t acc 95.000 (97.436)\n",
      "Test\t  accuracy: 81.750 (Err: 1.700 )\n",
      "\n",
      "Epoch: [318]\t Loss 0.5976 (0.5302)\t acc 96.250 (97.348)\n",
      "Test\t  accuracy: 82.720 (Err: 1.701 )\n",
      "\n",
      "Epoch: [319]\t Loss 0.4821 (0.5172)\t acc 98.750 (97.414)\n",
      "Test\t  accuracy: 81.990 (Err: 1.844 )\n",
      "\n",
      "Epoch: [320]\t Loss 0.3890 (0.5204)\t acc 98.750 (97.424)\n",
      "Test\t  accuracy: 80.850 (Err: 1.781 )\n",
      "\n",
      "Epoch: [321]\t Loss 0.4576 (0.5185)\t acc 97.500 (97.390)\n",
      "Test\t  accuracy: 81.370 (Err: 1.808 )\n",
      "\n",
      "Epoch: [322]\t Loss 0.3951 (0.5151)\t acc 98.750 (97.488)\n",
      "Test\t  accuracy: 81.870 (Err: 1.823 )\n",
      "\n",
      "Epoch: [323]\t Loss 0.6112 (0.5178)\t acc 95.000 (97.366)\n",
      "Test\t  accuracy: 81.750 (Err: 1.830 )\n",
      "\n",
      "Epoch: [324]\t Loss 0.7209 (0.5112)\t acc 93.750 (97.482)\n",
      "Test\t  accuracy: 81.860 (Err: 1.822 )\n",
      "\n",
      "Epoch: [325]\t Loss 0.7639 (0.5160)\t acc 95.000 (97.506)\n",
      "Test\t  accuracy: 82.370 (Err: 1.696 )\n",
      "\n",
      "Epoch: [326]\t Loss 0.5383 (0.5161)\t acc 96.250 (97.392)\n",
      "Test\t  accuracy: 80.670 (Err: 1.810 )\n",
      "\n",
      "Epoch: [327]\t Loss 0.4875 (0.5092)\t acc 98.750 (97.604)\n",
      "Test\t  accuracy: 82.010 (Err: 1.765 )\n",
      "\n",
      "Epoch: [328]\t Loss 0.4441 (0.5153)\t acc 97.500 (97.492)\n",
      "Test\t  accuracy: 81.670 (Err: 1.880 )\n",
      "\n",
      "Epoch: [329]\t Loss 0.6062 (0.5147)\t acc 92.500 (97.404)\n",
      "Test\t  accuracy: 81.780 (Err: 1.713 )\n",
      "\n",
      "Epoch: [330]\t Loss 0.4883 (0.5092)\t acc 98.750 (97.544)\n",
      "Test\t  accuracy: 81.950 (Err: 1.772 )\n",
      "\n",
      "Epoch: [331]\t Loss 0.4280 (0.5129)\t acc 97.500 (97.708)\n",
      "Test\t  accuracy: 81.360 (Err: 1.764 )\n",
      "\n",
      "Epoch: [332]\t Loss 0.5759 (0.5176)\t acc 93.750 (97.354)\n",
      "Test\t  accuracy: 82.190 (Err: 1.789 )\n",
      "\n",
      "Epoch: [333]\t Loss 0.4060 (0.5137)\t acc 98.750 (97.492)\n",
      "Test\t  accuracy: 81.600 (Err: 1.841 )\n",
      "\n",
      "Epoch: [334]\t Loss 0.3952 (0.5279)\t acc 100.000 (97.466)\n",
      "Test\t  accuracy: 82.100 (Err: 1.760 )\n",
      "\n",
      "Epoch: [335]\t Loss 0.7109 (0.5100)\t acc 96.250 (97.572)\n",
      "Test\t  accuracy: 82.010 (Err: 1.733 )\n",
      "\n",
      "Epoch: [336]\t Loss 0.4779 (0.5099)\t acc 98.750 (97.538)\n",
      "Test\t  accuracy: 81.910 (Err: 1.799 )\n",
      "\n",
      "Epoch: [337]\t Loss 0.4339 (0.5202)\t acc 97.500 (97.502)\n",
      "Test\t  accuracy: 82.160 (Err: 1.747 )\n",
      "\n",
      "Epoch: [338]\t Loss 0.5873 (0.5051)\t acc 97.500 (97.598)\n",
      "Test\t  accuracy: 81.130 (Err: 1.790 )\n",
      "\n",
      "Epoch: [339]\t Loss 0.7344 (0.5190)\t acc 96.250 (97.556)\n",
      "Test\t  accuracy: 81.790 (Err: 1.789 )\n",
      "\n",
      "Epoch: [340]\t Loss 0.6745 (0.5140)\t acc 96.250 (97.452)\n",
      "Test\t  accuracy: 81.670 (Err: 1.788 )\n",
      "\n",
      "Epoch: [341]\t Loss 0.3859 (0.5213)\t acc 98.750 (97.460)\n",
      "Test\t  accuracy: 82.130 (Err: 1.726 )\n",
      "\n",
      "Epoch: [342]\t Loss 0.5479 (0.5046)\t acc 98.750 (97.600)\n",
      "Test\t  accuracy: 81.930 (Err: 1.783 )\n",
      "\n",
      "Epoch: [343]\t Loss 0.5445 (0.5110)\t acc 97.500 (97.532)\n",
      "Test\t  accuracy: 83.220 (Err: 1.672 )\n",
      "\n",
      "Epoch: [344]\t Loss 0.6306 (0.5078)\t acc 97.500 (97.614)\n",
      "Test\t  accuracy: 82.080 (Err: 1.725 )\n",
      "\n",
      "Epoch: [345]\t Loss 0.7184 (0.5263)\t acc 97.500 (97.424)\n",
      "Test\t  accuracy: 81.470 (Err: 1.714 )\n",
      "\n",
      "Epoch: [346]\t Loss 0.7378 (0.5042)\t acc 96.250 (97.586)\n",
      "Test\t  accuracy: 82.430 (Err: 1.720 )\n",
      "\n",
      "Epoch: [347]\t Loss 0.5552 (0.5210)\t acc 95.000 (97.432)\n",
      "Test\t  accuracy: 82.160 (Err: 1.789 )\n",
      "\n",
      "Epoch: [348]\t Loss 0.6406 (0.5147)\t acc 100.000 (97.522)\n",
      "Test\t  accuracy: 80.820 (Err: 1.837 )\n",
      "\n",
      "Epoch: [349]\t Loss 0.3846 (0.5012)\t acc 100.000 (97.718)\n",
      "Test\t  accuracy: 81.590 (Err: 1.816 )\n",
      "\n",
      "Epoch: [350]\t Loss 0.5471 (0.5096)\t acc 100.000 (97.522)\n",
      "Test\t  accuracy: 82.050 (Err: 1.753 )\n",
      "\n",
      "Epoch: [351]\t Loss 0.7360 (0.5165)\t acc 95.000 (97.528)\n",
      "Test\t  accuracy: 80.880 (Err: 1.885 )\n",
      "\n",
      "Epoch: [352]\t Loss 0.4435 (0.5146)\t acc 98.750 (97.502)\n",
      "Test\t  accuracy: 81.490 (Err: 1.802 )\n",
      "\n",
      "Epoch: [353]\t Loss 0.6385 (0.4987)\t acc 95.000 (97.710)\n",
      "Test\t  accuracy: 81.180 (Err: 1.779 )\n",
      "\n",
      "Epoch: [354]\t Loss 0.5633 (0.5179)\t acc 98.750 (97.522)\n",
      "Test\t  accuracy: 81.990 (Err: 1.838 )\n",
      "\n",
      "Epoch: [355]\t Loss 0.5082 (0.5164)\t acc 96.250 (97.490)\n",
      "Test\t  accuracy: 82.060 (Err: 1.796 )\n",
      "\n",
      "Epoch: [356]\t Loss 0.2879 (0.4967)\t acc 98.750 (97.612)\n",
      "Test\t  accuracy: 81.250 (Err: 1.890 )\n",
      "\n",
      "Epoch: [357]\t Loss 0.4864 (0.5160)\t acc 97.500 (97.446)\n",
      "Test\t  accuracy: 81.430 (Err: 1.747 )\n",
      "\n",
      "Epoch: [358]\t Loss 0.5096 (0.5184)\t acc 95.000 (97.488)\n",
      "Test\t  accuracy: 82.220 (Err: 1.761 )\n",
      "\n",
      "Epoch: [359]\t Loss 0.7560 (0.5061)\t acc 95.000 (97.534)\n",
      "Test\t  accuracy: 82.130 (Err: 1.751 )\n",
      "\n",
      "Epoch: [360]\t Loss 0.4940 (0.5124)\t acc 96.250 (97.428)\n",
      "Test\t  accuracy: 82.040 (Err: 1.724 )\n",
      "\n",
      "Epoch: [361]\t Loss 0.5864 (0.5168)\t acc 93.750 (97.542)\n",
      "Test\t  accuracy: 81.770 (Err: 1.785 )\n",
      "\n",
      "Epoch: [362]\t Loss 0.5914 (0.5127)\t acc 97.500 (97.558)\n",
      "Test\t  accuracy: 80.820 (Err: 1.866 )\n",
      "\n",
      "Epoch: [363]\t Loss 0.6244 (0.5180)\t acc 93.750 (97.380)\n",
      "Test\t  accuracy: 81.620 (Err: 1.663 )\n",
      "\n",
      "Epoch: [364]\t Loss 0.6797 (0.5161)\t acc 97.500 (97.508)\n",
      "Test\t  accuracy: 81.640 (Err: 1.777 )\n",
      "\n",
      "Epoch: [365]\t Loss 0.5695 (0.4993)\t acc 95.000 (97.622)\n",
      "Test\t  accuracy: 82.130 (Err: 1.779 )\n",
      "\n",
      "Epoch: [366]\t Loss 0.5626 (0.5070)\t acc 98.750 (97.680)\n",
      "Test\t  accuracy: 81.620 (Err: 1.805 )\n",
      "\n",
      "Epoch: [367]\t Loss 0.5379 (0.5019)\t acc 96.250 (97.640)\n",
      "Test\t  accuracy: 82.120 (Err: 1.802 )\n",
      "\n",
      "Epoch: [368]\t Loss 0.4060 (0.5082)\t acc 98.750 (97.546)\n",
      "Test\t  accuracy: 81.560 (Err: 1.848 )\n",
      "\n",
      "Epoch: [369]\t Loss 0.5335 (0.4988)\t acc 97.500 (97.616)\n",
      "Test\t  accuracy: 82.370 (Err: 1.759 )\n",
      "\n",
      "Epoch: [370]\t Loss 0.4472 (0.4902)\t acc 100.000 (97.774)\n",
      "Test\t  accuracy: 81.380 (Err: 1.834 )\n",
      "\n",
      "Epoch: [371]\t Loss 0.5343 (0.5017)\t acc 97.500 (97.622)\n",
      "Test\t  accuracy: 82.250 (Err: 1.775 )\n",
      "\n",
      "Epoch: [372]\t Loss 0.6513 (0.5011)\t acc 95.000 (97.610)\n",
      "Test\t  accuracy: 82.310 (Err: 1.784 )\n",
      "\n",
      "Epoch: [373]\t Loss 0.5752 (0.4969)\t acc 96.250 (97.698)\n",
      "Test\t  accuracy: 82.070 (Err: 1.754 )\n",
      "\n",
      "Epoch: [374]\t Loss 0.7801 (0.5046)\t acc 95.000 (97.618)\n",
      "Test\t  accuracy: 81.230 (Err: 1.750 )\n",
      "\n",
      "Epoch: [375]\t Loss 0.5297 (0.5087)\t acc 97.500 (97.514)\n",
      "Test\t  accuracy: 82.210 (Err: 1.700 )\n",
      "\n",
      "Epoch: [376]\t Loss 0.4066 (0.5065)\t acc 98.750 (97.576)\n",
      "Test\t  accuracy: 81.720 (Err: 1.782 )\n",
      "\n",
      "Epoch: [377]\t Loss 0.4860 (0.5145)\t acc 96.250 (97.360)\n",
      "Test\t  accuracy: 81.830 (Err: 1.740 )\n",
      "\n",
      "Epoch: [378]\t Loss 0.4735 (0.4986)\t acc 97.500 (97.702)\n",
      "Test\t  accuracy: 81.490 (Err: 1.843 )\n",
      "\n",
      "Epoch: [379]\t Loss 0.5791 (0.5031)\t acc 97.500 (97.636)\n",
      "Test\t  accuracy: 82.280 (Err: 1.704 )\n",
      "\n",
      "Epoch: [380]\t Loss 0.5635 (0.5083)\t acc 97.500 (97.602)\n",
      "Test\t  accuracy: 81.850 (Err: 1.848 )\n",
      "\n",
      "Epoch: [381]\t Loss 0.3516 (0.5075)\t acc 97.500 (97.550)\n",
      "Test\t  accuracy: 80.780 (Err: 1.906 )\n",
      "\n",
      "Epoch: [382]\t Loss 0.6852 (0.5085)\t acc 98.750 (97.650)\n",
      "Test\t  accuracy: 82.230 (Err: 1.709 )\n",
      "\n",
      "Epoch: [383]\t Loss 0.5681 (0.4976)\t acc 96.250 (97.690)\n",
      "Test\t  accuracy: 82.580 (Err: 1.707 )\n",
      "\n",
      "Epoch: [384]\t Loss 0.7034 (0.5150)\t acc 96.250 (97.436)\n",
      "Test\t  accuracy: 81.880 (Err: 1.807 )\n",
      "\n",
      "Epoch: [385]\t Loss 0.5037 (0.4870)\t acc 98.750 (97.668)\n",
      "Test\t  accuracy: 81.260 (Err: 1.776 )\n",
      "\n",
      "Epoch: [386]\t Loss 0.6759 (0.5008)\t acc 98.750 (97.582)\n",
      "Test\t  accuracy: 81.110 (Err: 1.913 )\n",
      "\n",
      "Epoch: [387]\t Loss 0.7130 (0.5059)\t acc 96.250 (97.554)\n",
      "Test\t  accuracy: 81.250 (Err: 1.829 )\n",
      "\n",
      "Epoch: [388]\t Loss 0.4982 (0.5090)\t acc 97.500 (97.578)\n",
      "Test\t  accuracy: 81.970 (Err: 1.729 )\n",
      "\n",
      "Epoch: [389]\t Loss 0.5874 (0.4994)\t acc 93.750 (97.636)\n",
      "Test\t  accuracy: 81.690 (Err: 1.848 )\n",
      "\n",
      "Epoch: [390]\t Loss 0.5429 (0.5033)\t acc 97.500 (97.580)\n",
      "Test\t  accuracy: 82.650 (Err: 1.683 )\n",
      "\n",
      "Epoch: [391]\t Loss 0.4302 (0.5029)\t acc 98.750 (97.566)\n",
      "Test\t  accuracy: 81.340 (Err: 1.918 )\n",
      "\n",
      "Epoch: [392]\t Loss 0.3149 (0.4916)\t acc 100.000 (97.664)\n",
      "Test\t  accuracy: 81.840 (Err: 1.879 )\n",
      "\n",
      "Epoch: [393]\t Loss 0.7153 (0.5016)\t acc 95.000 (97.614)\n",
      "Test\t  accuracy: 82.120 (Err: 1.921 )\n",
      "\n",
      "Epoch: [394]\t Loss 0.4750 (0.4932)\t acc 96.250 (97.756)\n",
      "Test\t  accuracy: 81.300 (Err: 1.816 )\n",
      "\n",
      "Epoch: [395]\t Loss 0.4859 (0.4873)\t acc 97.500 (97.766)\n",
      "Test\t  accuracy: 82.280 (Err: 1.747 )\n",
      "\n",
      "Epoch: [396]\t Loss 0.4259 (0.4920)\t acc 98.750 (97.646)\n",
      "Test\t  accuracy: 81.810 (Err: 1.799 )\n",
      "\n",
      "Epoch: [397]\t Loss 0.5924 (0.5034)\t acc 100.000 (97.598)\n",
      "Test\t  accuracy: 81.930 (Err: 1.849 )\n",
      "\n",
      "Epoch: [398]\t Loss 0.5765 (0.4889)\t acc 97.500 (97.732)\n",
      "Test\t  accuracy: 81.200 (Err: 1.951 )\n",
      "\n",
      "Epoch: [399]\t Loss 0.4910 (0.5018)\t acc 97.500 (97.594)\n",
      "Test\t  accuracy: 80.930 (Err: 1.758 )\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'cuda'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-07f27b80a9fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mmodel_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmodel_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'cuda'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    model_info = main(model)\n",
    "    model_info.cuda()\n",
    "    print(model_info)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ba9ca613c00912bf2bb7336c6f7b766b0be232b7fbb6881178983a86316f18c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
